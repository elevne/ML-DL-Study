{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47dd3471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (미니배치)확률 경사하강법을 위해 필요한 \n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb9109dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 정의해두기\n",
    "M = 2 #입력데이터 차원\n",
    "K = 3 #클래스 수\n",
    "n = 100 #각 클래스에 있는 데이터 수\n",
    "N = n*K #전체 데이터 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00c9b018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플데이터 생성\n",
    "X1 = np.random.randn(n, M) + np.array([0, 10])\n",
    "X2 = np.random.randn(n, M) + np.array([5, 5])\n",
    "X3 = np.random.randn(n, M) + np.array([10, 0])\n",
    "\n",
    "Y1 = np.array([[1, 0, 0] for i in range(n)])\n",
    "Y2 = np.array([[0, 1, 0] for i in range(n)])\n",
    "Y3 = np.array([[0, 0, 1] for i in range(n)])\n",
    "\n",
    "X = np.concatenate((X1, X2, X3), axis=0)\n",
    "Y = np.concatenate((Y1, Y2, Y3), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b32a41ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이진분류에서 Sigmoid 였던 부분을 Softmax로 변형만 하면 다중클래스로 분류하는 것 출력 가능\n",
    "W = tf.Variable(tf.zeros([M, K]))\n",
    "b = tf.Variable(tf.zeros([K]))\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, M])\n",
    "t = tf.placeholder(tf.float32, shape=[None, K])\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ba85825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차함수 정의해주기 (Cross_entropy)\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(t*tf.log(y), reduction_indices=[1])) # reduction_indices는 행렬의 합 방향을 정해주는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "311e01c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경사하강법~\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62aee049",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(t, 1)) # 예측값과 결과값이 맞는지 확인하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8db1cb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50 # 미니배치 크기\n",
    "n_batches = N //batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e784be41",
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86c31a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확률경사하강에서는 각 에폭마다 데이터를 섞으며 실제로 학습을 수행하는 코드는 아래와 같음\n",
    "for epoch in range(20):\n",
    "    X_, Y_ = shuffle(X, Y)\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        start = i*batch_size\n",
    "        end = start + batch_size\n",
    "        \n",
    "        sess.run(train_step, feed_dict={\n",
    "            x:X_[start:end],\n",
    "            t:Y_[start:end]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "baed2e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "\n",
      "Output Probability\n",
      "[[7.0767275e-10 1.5523518e-03 9.9844766e-01]\n",
      " [4.5982271e-09 7.8458088e-03 9.9215418e-01]\n",
      " [9.9729162e-01 2.7083482e-03 7.5318818e-10]\n",
      " [9.9565142e-01 4.3485877e-03 2.7380603e-08]\n",
      " [2.5889883e-03 9.6762854e-01 2.9782459e-02]\n",
      " [1.1636893e-09 2.9577001e-03 9.9704224e-01]\n",
      " [1.5350128e-07 1.1909149e-02 9.8809063e-01]\n",
      " [6.9761185e-08 1.9177491e-02 9.8082238e-01]\n",
      " [9.9973887e-01 2.6110641e-04 1.4702017e-10]\n",
      " [3.3475664e-09 5.0440622e-03 9.9495596e-01]]\n"
     ]
    }
   ],
   "source": [
    "# 결과 확인해보기\n",
    "X_, Y_ = shuffle(X, Y)\n",
    "\n",
    "classified = correct_prediction.eval(session=sess, feed_dict={\n",
    "    x:X_[0:10], t:Y_[0:10]\n",
    "})\n",
    "prob = y.eval(session=sess, feed_dict={\n",
    "    x:X_[0:10]\n",
    "})\n",
    "\n",
    "print('Classified')\n",
    "print(classified)\n",
    "print()\n",
    "print('Output Probability')\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f18f24a",
   "metadata": {},
   "source": [
    "### 이번에는 또 Keras로 구현해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76cd9c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2553e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(input_dim=M, units=K))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6274737a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300 samples\n",
      "Epoch 1/20\n",
      "300/300 [==============================] - 1s 4ms/sample - loss: 0.6177\n",
      "Epoch 2/20\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.0508\n",
      "Epoch 3/20\n",
      "300/300 [==============================] - 0s 63us/sample - loss: 0.0458\n",
      "Epoch 4/20\n",
      "300/300 [==============================] - 0s 67us/sample - loss: 0.0432\n",
      "Epoch 5/20\n",
      "300/300 [==============================] - 0s 60us/sample - loss: 0.0405\n",
      "Epoch 6/20\n",
      "300/300 [==============================] - 0s 60us/sample - loss: 0.0386\n",
      "Epoch 7/20\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.0364\n",
      "Epoch 8/20\n",
      "300/300 [==============================] - 0s 60us/sample - loss: 0.0346\n",
      "Epoch 9/20\n",
      "300/300 [==============================] - 0s 60us/sample - loss: 0.0332\n",
      "Epoch 10/20\n",
      "300/300 [==============================] - 0s 63us/sample - loss: 0.0318\n",
      "Epoch 11/20\n",
      "300/300 [==============================] - 0s 60us/sample - loss: 0.0309\n",
      "Epoch 12/20\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.0297\n",
      "Epoch 13/20\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.0286\n",
      "Epoch 14/20\n",
      "300/300 [==============================] - 0s 60us/sample - loss: 0.0278\n",
      "Epoch 15/20\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.0270\n",
      "Epoch 16/20\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.0261\n",
      "Epoch 17/20\n",
      "300/300 [==============================] - 0s 60us/sample - loss: 0.0257\n",
      "Epoch 18/20\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.0248\n",
      "Epoch 19/20\n",
      "300/300 [==============================] - 0s 60us/sample - loss: 0.0240\n",
      "Epoch 20/20\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.0235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x287749b5370>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minibatch_size = 50\n",
    "model.fit(X, Y, epochs=20, batch_size=minibatch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6352be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Main\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.2512995e-02, 9.8428059e-01, 3.2064163e-03],\n",
       "       [9.9778509e-01, 2.2148939e-03, 1.1563247e-09],\n",
       "       [1.4187043e-09, 5.3567705e-03, 9.9464321e-01],\n",
       "       [9.9543446e-01, 4.5655523e-03, 1.9934296e-09],\n",
       "       [1.4097329e-02, 9.8362768e-01, 2.2750632e-03],\n",
       "       [4.5600537e-11, 5.1459153e-03, 9.9485415e-01],\n",
       "       [4.4743448e-08, 3.6489367e-02, 9.6351057e-01],\n",
       "       [9.6245505e-02, 9.0240645e-01, 1.3479975e-03],\n",
       "       [9.9745041e-01, 2.5495416e-03, 1.6806589e-10],\n",
       "       [1.2363078e-09, 5.0999224e-03, 9.9490005e-01]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_, Y_ = shuffle(X, Y)\n",
    "classes = model.predict(X_[0:10], batch_size=minibatch_size)\n",
    "classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
