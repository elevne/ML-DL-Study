{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "082906f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "import numpy as np\n",
    "\n",
    "komoran = Komoran()\n",
    "text = \"오늘 날씨는 구름이 많아요\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61ce1d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오늘', '날씨', '구름']\n"
     ]
    }
   ],
   "source": [
    "nouns = komoran.nouns(text)\n",
    "print(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb69796e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'오늘': 0, '날씨': 1, '구름': 2}\n"
     ]
    }
   ],
   "source": [
    "# 단어사전 구축 및 단어별 인덱스 부여해주기\n",
    "dics = {}\n",
    "for word in nouns:\n",
    "    if word not in dics.keys():\n",
    "        dics[word] = len(dics)\n",
    "print(dics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "795953e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# 원핫 인코딩\n",
    "nb_classes = len(dics)\n",
    "targets = list(dics.values())\n",
    "one_hot_targets = np.eye(nb_classes)[targets]\n",
    "print(one_hot_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d69fbcec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 원핫인코딩은 단점이 많음... => 분산표현 방식을 채택하는 것으로~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b57fd4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) 말뭉치 데이터 읽기 시작\n",
      "200000\n",
      "1) 말뭉치 데이터 읽기 완료: 2.1409778594970703\n",
      "2) 형태소에서 명사만 추출 시작\n",
      "2) 형태소에서 명사만 추출 완료: 72.15831160545349\n",
      "3) Word2Vec 모델 학습 시작\n",
      "3) Word2Vec 모델 학습 완료: 85.46841812133789\n",
      "4) 학습된 모델 저장\n",
      "4) 학습도니 모델 저장 완료: 85.7264769077301\n",
      "corpus count: 200000\n",
      "corpus total words: 1076899\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from konlpy.tag import Komoran\n",
    "import time\n",
    "\n",
    "# 데이터 읽어오기\n",
    "def read_review_data(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = [line.split('\\t') for line in f.read().splitlines()]\n",
    "        data = data[1:] #헤더제거\n",
    "    return data\n",
    "# 학습시간 측정\n",
    "start = time.time()\n",
    "\n",
    "# 리뷰파일 읽기\n",
    "print('1) 말뭉치 데이터 읽기 시작')\n",
    "review_data = read_review_data('./ratings.txt')\n",
    "print(len(review_data))\n",
    "print('1) 말뭉치 데이터 읽기 완료:', time.time() - start)\n",
    "\n",
    "# 문장 단위로 명사만 추출해 학습 입력 데이터로 만들기\n",
    "print('2) 형태소에서 명사만 추출 시작')\n",
    "komoran = Komoran()\n",
    "docs = [komoran.nouns(sentence[1]) for sentence in review_data]\n",
    "print('2) 형태소에서 명사만 추출 완료:', time.time() - start)\n",
    "\n",
    "# Word2Vec 모델 학습\n",
    "print('3) Word2Vec 모델 학습 시작')\n",
    "model = Word2Vec(sentences=docs, vector_size=200, window=4, hs=1, min_count=2, sg=1)\n",
    "print('3) Word2Vec 모델 학습 완료:', time.time() - start)\n",
    "\n",
    "# 모델 저장\n",
    "print('4) 학습된 모델 저장')\n",
    "model.save('nvmc.model')\n",
    "print('4) 학습된 모델 저장 완료:', time.time() - start)\n",
    "\n",
    "# 학습된 말뭉치 수, 코퍼스 내 전체 단어 수\n",
    "print('corpus count:', model.corpus_count) # 말뭉치 수\n",
    "print('corpus total words:', model.corpus_total_words) # 단어 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "358ed64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus_total_words: 1076899\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec.load('nvmc.model')\n",
    "print('Corpus_total_words:', model.corpus_total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93c5afd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사랑: [-0.09963502 -0.51247454  0.30768812 -0.07181589  0.16950014 -0.27226546\n",
      " -0.20034589  0.20808795 -0.0278259   0.31236452  0.05347251 -0.05940739\n",
      "  0.29611224 -0.0622078  -0.16552979  0.32803574 -0.09007484 -0.07510316\n",
      "  0.14407587 -0.31191877  0.25298133  0.16413441 -0.3008848   0.20796376\n",
      " -0.40281355 -0.19278833  0.00496402 -0.1483992  -0.17066455 -0.21005322\n",
      " -0.00663083 -0.10731995 -0.03389509 -0.11334454  0.0316027   0.25160068\n",
      "  0.12745164  0.02471401  0.02739664  0.00912736 -0.2070161  -0.1329094\n",
      " -0.43163353 -0.48274696  0.5291333   0.13072701  0.03685965 -0.00268602\n",
      "  0.3482423   0.00807548  0.08908078 -0.31108728 -0.02584817  0.03388226\n",
      "  0.15197004 -0.07177763  0.23828048 -0.26313645  0.30797178  0.03409517\n",
      " -0.06699759  0.1264337  -0.41427356  0.14593731 -0.13872607 -0.18302204\n",
      " -0.33259308  0.0593227   0.02350021  0.24098799 -0.2289866  -0.39240658\n",
      "  0.03107566  0.11131877  0.13886136  0.0052525   0.25983262 -0.2097386\n",
      " -0.20219477  0.01825125  0.12977855 -0.05343376  0.05346502  0.3965505\n",
      " -0.24603389 -0.16646825 -0.04610246  0.08383963 -0.02139442 -0.07234139\n",
      "  0.05664367  0.19555622 -0.00082118 -0.10701016  0.41724765  0.11893006\n",
      "  0.01345989 -0.24377666  0.09481951 -0.02287113 -0.32828292  0.473093\n",
      "  0.37106404  0.16881764  0.01400206 -0.24515812  0.19996673  0.4337171\n",
      " -0.09509426 -0.18707211  0.02178152 -0.48497215 -0.33391482 -0.10594118\n",
      "  0.19291136 -0.30992907 -0.02905055 -0.31534183  0.06782007 -0.07257185\n",
      " -0.12976545 -0.13295366  0.13719127 -0.06611276 -0.09317833  0.4817451\n",
      " -0.03578609  0.2912128   0.21205674 -0.06820425 -0.09986179  0.17921773\n",
      " -0.2744507   0.03431027  0.18581249  0.328164   -0.05560736 -0.00058256\n",
      "  0.04155516 -0.04832712 -0.07951729 -0.0913654  -0.29873282 -0.03837697\n",
      "  0.13221128  0.0551744  -0.22446764 -0.08545523 -0.12376955 -0.12921244\n",
      " -0.01296295 -0.33977765 -0.02109951 -0.22482252 -0.31088352  0.06301466\n",
      "  0.40526038  0.12097277  0.14196466 -0.21143568 -0.24060836 -0.07855207\n",
      " -0.09520826 -0.28662768 -0.2769267  -0.02764553  0.02642111 -0.04837702\n",
      "  0.07352351  0.00370898 -0.48536956  0.13115562  0.39948875 -0.16166666\n",
      "  0.0793162  -0.13308577  0.13211286 -0.1082311   0.28876087 -0.21974757\n",
      " -0.10282554 -0.03950103  0.08694974  0.04788318 -0.17278296 -0.05364748\n",
      " -0.01782059  0.04134861  0.01526293 -0.04356888  0.24884051  0.01284484\n",
      "  0.09615253  0.12805079  0.30916545 -0.15850039  0.05587914  0.16468309\n",
      "  0.07458252  0.18012057]\n"
     ]
    }
   ],
   "source": [
    "# '사랑'이라는 단어로 생성한 단어 임베딩 벡터\n",
    "print('사랑:', model.wv['사랑'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "234994c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "일요일 = 월요일\t 0.6136624\n",
      "안성기 = 배우\t 0.51435363\n",
      "대기업 = 삼성\t 0.53871554\n",
      "일요일 != 삼성\t 0.27813858\n",
      "히어로 != 삼성\t 0.1362387\n"
     ]
    }
   ],
   "source": [
    "# 단어 유사도 계산해보기\n",
    "print('일요일 = 월요일\\t', model.wv.similarity(w1='일요일', w2='월요일'))\n",
    "print('안성기 = 배우\\t', model.wv.similarity(w1='안성기', w2='배우'))\n",
    "print('대기업 = 삼성\\t', model.wv.similarity(w1='대기업', w2='삼성'))\n",
    "print('일요일 != 삼성\\t', model.wv.similarity(w1='일요일', w2='삼성'))\n",
    "print('히어로 != 삼성\\t', model.wv.similarity(w1='히어로', w2='삼성'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbfaef66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('장미희', 0.6895906329154968), ('현영', 0.6719661951065063), ('조한선', 0.6692084670066833), ('박신양', 0.6639488339424133), ('김희원', 0.6611346006393433)]\n",
      "[('더 울버린', 0.6350187063217163), ('캐리비안의 해적', 0.6309864521026611), ('나니아 연대기', 0.6261622905731201), ('엑스맨', 0.6226657032966614), ('러시아워', 0.6181084513664246)]\n"
     ]
    }
   ],
   "source": [
    "# 가장 유사한 단어 추출\n",
    "print(model.wv.most_similar('안성기', topn=5))\n",
    "print(model.wv.most_similar('시리즈', topn=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
